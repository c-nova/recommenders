{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (c) Microsoft Corporation. All rights reserved.*\n",
    "\n",
    "*Licensed under the MIT License.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movielens データセットでのリーマン低ランク行列補完アルゴリズム\r\n",
    "\r\n",
    "リーマン低ランク行列補完 (RLRMC)は、リーマン共役勾配アルゴリズム (Absil et al., 2008) を用いて最適化問題を解決する行列分解法(バニラ)行列補完アルゴリズムである。RLRMCは、Jawanpuria と Mishra (2018) と Mishra et al. (2013) の論文に基づいています。\r\n",
    "\r\n",
    "映画 (アイテム) とユーザーの評価マトリックスは、低ランクのマトリックスとしてモデル化されます。映画の数を $d$、 ユーザーの数を $T$ にしましょう。RLRMC アルゴリズムは、評価行列 $M$ (大きさは $d\\回数 T$) が部分的に既知であると仮定します。$M(i,j)$ のエントリは、$i$-th ムービーに対して $j$-th ユーザーによって与えられた評価を表します。$M=LR^\\top$ は RLRMC 学習行列 $M$ であり、$L$ は $d\\回数 r$ 行列で、$R$ は $T\\回数 r$ となります。ここでは、$r$ は RLRMCアルゴリズムに提供する必要がある順位ハイパーパラメータです。通常、$r\\ll d,T$ であると仮定されます。最適化問題は、リーマン共役勾配アルゴリズムを使用して反復的に解決されます。リーマン最適化フレームワークは、共役勾配、信頼領域などのユークリッドの一次アルゴリズムと二次アルゴリズムを、とりわけリーマン多様体に汎化します。リーマン最適化フレームワークの詳細な説明は、Absil et al. (2008) で確認できます。\r\n",
    "\r\n",
    "このノートブックでは、**reco_utils** を利用した RLRMC 実装を利用して評価する方法の例を示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import sys\r\n",
    "import time\r\n",
    "import pandas as pd\r\n",
    "sys.path.append(\"../../\")\r\n",
    "sys.path.append(\"../../reco_utils/recommender/rlrmc/\")\r\n",
    "\r\n",
    "from reco_utils.dataset.python_splitters import python_random_split\r\n",
    "from reco_utils.dataset.python_splitters import python_stratified_split\r\n",
    "from reco_utils.dataset import movielens\r\n",
    "from reco_utils.recommender.rlrmc.RLRMCdataset import RLRMCdataset \r\n",
    "from reco_utils.recommender.rlrmc.RLRMCalgorithm import RLRMCalgorithm \r\n",
    "# Pymanopt のインストールは以下の内容の実行が必要です\r\n",
    "# pip install pymanopt \r\n",
    "from reco_utils.evaluation.python_evaluation import (\r\n",
    "    rmse, mae\r\n",
    ")\r\n",
    "\r\n",
    "# import logging\r\n",
    "\r\n",
    "# %load_ext autoreload\r\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 0.23.4\n",
      "System version: 3.7.1 (default, Dec 14 2018, 13:28:58) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"System version: {}\".format(sys.version))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "デフォルトパラメータを設定します。\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Movielens のデータサイズを選択: 100k, 1m, 10m, or 20m\r\n",
    "MOVIELENS_DATA_SIZE = '10m'\r\n",
    "\r\n",
    "# モデル パラメータ\r\n",
    "\r\n",
    "# 正の整数(通常は小さい)を持つモデルのランク。必須パラメータです\r\n",
    "rank_parameter = 10\r\n",
    "# 正の数 (通常は小さい) を持つ損失関数に乗算された正規化パラメータ。必須パラメータです\r\n",
    "regularization_parameter = 0.001\r\n",
    "# 'svd' 単数値分解を採用した、モデルの初期化オプション。オプションのパラメータです\r\n",
    "initialization_flag = 'svd' #default is 'random'\r\n",
    "# 正の整数を持つソルバーの最大反復回数。オプションのパラメータです\r\n",
    "maximum_iteration = 100 #optional, default is 100\r\n",
    "# 正の整数を持つソルバーの最大時間 (秒)。オプションのパラメータです\r\n",
    "maximum_time = 300#optional, default is 1000\r\n",
    "\r\n",
    "# 中間結果の詳細度\r\n",
    "verbosity=0 #オプションのパラメータであり、有効な値は 0,1,2、デフォルトは 0 です\r\n",
    "# 反復単位のトレーニング RMSE を計算するかどうか (およびテスト データが与えられている場合は RMSE をテストする)\r\n",
    "compute_iter_rmse=True #オプションのパラメータであり、ブール値、デフォルトは False です"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ロギング ユーティリティ。次のコマンドを使用するためには 'logging' をインポートしてください。\r\n",
    "# logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MovieLens データセットをダウンロードする\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65.6MB [00:25, 2.57MB/s]                            \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=[\"userID\", \"itemID\", \"rating\", \"timestamp\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ユーティリティで提供されている Spark の時系列分割器を使用してデータを分割する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 検証とテストセットの両方が必要な場合\r\n",
    "# train, validation, test = python_random_split(df,[0.6, 0.2, 0.2])\r\n",
    "\r\n",
    "## 検証セットが必要ない場合\r\n",
    "train, test = python_random_split(df,[0.8, 0.2])\r\n",
    "\r\n",
    "## テストセットが不要な場合\r\n",
    "# train, validation = python_random_split(df,[0.8, 0.2])\r\n",
    "\r\n",
    "## 検証セットとテストセットの両方が必要ない場合(つまり、完全なデータセットはモデルのトレーニング用)\r\n",
    "# train = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ サブセットから RLRMCdataset オブジェクトを生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = RLRMCdataset(train=train, validation=validation, test=test)\n",
    "data = RLRMCdataset(train=train, test=test) # No validation set\n",
    "# data = RLRMCdataset(train=train, validation=validation) # No test set\n",
    "# data = RLRMCdataset(train=train) # No validation or test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. トレーニング データでの RLRMC モデルのトレーニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RLRMCalgorithm(rank = rank_parameter,\n",
    "                       C = regularization_parameter,\n",
    "                       model_param = data.model_param,\n",
    "                       initialize_flag = initialization_flag,\n",
    "                       maxiter=maximum_iteration,\n",
    "                       max_time=maximum_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 44.991251945495605 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\r\n",
    "\r\n",
    "model.fit(data,verbosity=verbosity)\r\n",
    "\r\n",
    "# fit_and_evaluateは、すべての反復で検証セット(指定されている場合)で RMSE を計算します\r\n",
    "# model.fit_and_evaluate(data,verbosity=verbosity)\r\n",
    "\r\n",
    "train_time = time.time() - start_time # train_time には、モデルの初期化とモデルのトレーニング時間の両方が含まれます。\r\n",
    "\r\n",
    "print(\"Took {} seconds for training.\".format(train_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. テストデータで RLRMC モデルから予測を取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Movielens 10m データセットから (userID,itemID) ペア (60586,54775) と (52681,36519) の予測を取得する\r\n",
    "# output = model.predict([60586,52681],[54775,36519]) # Movielens 10m データセット\r\n",
    "\r\n",
    "# 完全なテスト セットの予測を取得する\r\n",
    "predictions_ndarr = model.predict(test['userID'].values,test['itemID'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. RLRMC のパフォーマンスを評価する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t0.809386\n",
      "MAE:\t0.620971\n"
     ]
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame(data={\"userID\": test['userID'].values, \"itemID\":test['itemID'].values, \"prediction\":predictions_ndarr})\r\n",
    "\r\n",
    "## RMSE の test を計算する\r\n",
    "eval_rmse = rmse(test, predictions_df)\r\n",
    "## MAE の test を計算する\r\n",
    "eval_mae = mae(test, predictions_df)\r\n",
    "\r\n",
    "print(\"RMSE:\\t%f\" % eval_rmse,\r\n",
    "      \"MAE:\\t%f\" % eval_mae, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "[1] Pratik Jawanpuria and Bamdev Mishra. *A unified framework for structured low-rank matrix learning*. In International Conference on Machine Learning, 2018.\n",
    "\n",
    "[2] Bamdev Mishra, Gilles Meyer, Francis Bach, and Rodolphe Sepulchre. *Low-rank optimization with trace norm penalty*. In SIAM Journal on Optimization 23(4):2124-2149, 2013.\n",
    "\n",
    "[3] James Townsend, Niklas Koep, and Sebastian Weichwald. *Pymanopt: A Python Toolbox for Optimization on Manifolds using Automatic Differentiation*. In Journal of Machine Learning Research 17(137):1-5, 2016.\n",
    "\n",
    "[4] P.-A. Absil, R. Mahony, and R. Sepulchre. *Optimization Algorithms on Matrix Manifolds*. Princeton University Press, Princeton, NJ, 2008.\n",
    "\n",
    "[5] A. Edelman, T. Arias, and S. Smith. *The geometry of algo- rithms with orthogonality constraints*. SIAM Journal on Matrix Analysis and Applications, 20(2):303–353, 1998."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('vscpy38': conda)",
   "name": "python385jvsc74a57bd0be443e4bb5ca2a0039df422708907d2b33984b7dfb9ef6e469c27513aa2f1c12"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "be443e4bb5ca2a0039df422708907d2b33984b7dfb9ef6e469c27513aa2f1c12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}