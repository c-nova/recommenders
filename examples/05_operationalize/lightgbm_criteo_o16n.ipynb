{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## リアルタイム コンテンツ ベース の パーソナライゼーション モデルをデプロイする\r\n",
    "\r\n",
    "このノートブックでは、企業が機械学習を使用したレコメンデーション システムを使用し、顧客に対してコンテンツ ベースのパーソナライゼーションを自動化する方法を示します。Azure Databricks は、ユーザーがアイテムに関与する確率を予測するモデルをトレーニングするために使用されます。さらにこの推論を使用して、ユーザーが最も消費する可能性が高いコンテンツに基づいてアイテムをランク付けできます。<br><br>\r\n",
    "このノートブックは、 [MMLSpark-LightGBM-Criteo notebook](../02_model/mmlspark_lightgbm_criteo.ipynb) でトレーニングされたコンテンツベースのパーソナライゼーションモデルなど、Spark ベースのモデル用のスケーラブルなリアルタイム スコアリング サービスを作成します。\r\n",
    "<br><br>\r\n",
    "### アーキテクチャ\r\n",
    "<img src=\"https://recodatasets.z20.web.core.windows.net/images/lightgbm_criteo_arch.svg\" alt=\"Architecture\">\r\n",
    "\r\n",
    "### 構成要素\r\n",
    "このアーキテクチャでは、以下の構成要素を使用します:<br>\r\n",
    "- [Azure Blob Storage](https://azure.microsoft.com/en-us/services/storage/blobs/) は非構造データの大量の蓄積に最適化されたストレージです。このケースでは、入力データの格納に使用されます。<br>\r\n",
    "- [Azure Databricks](https://azure.microsoft.com/en-us/services/databricks/) はマネージドな Apache Spark クラスタであり、このケースではモデルのトレーニング及び評価に使用されます。<br>\r\n",
    "- [Azure Machine Learning](https://azure.microsoft.com/en-us/services/machine-learning-service/) はこのシナリオでは機械学習モデルの登録に使用されます。<br>\r\n",
    "- [Azure Container Registry](https://azure.microsoft.com/en-us/services/container-registry/) は本番環境でモデルの提供に使用するために、コンテナとしてスコアリング スクリプトをパッケージするために使用されます。<br>\r\n",
    "- [Azure Kubernetes Service](https://azure.microsoft.com/en-us/services/kubernetes-service/) はトレーニングされたモデルを Web または App Services として展開するために使用されます。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前提条件\r\n",
    "このノートブックを実行するには、以下の項目が完了していることを前提としています:\r\n",
    "\r\n",
    "1. モデルが[mmlspark_lightgbm_criteo](../02_model_content_based_filtering/mmlspark_lightgbm_criteo.ipynb)ノートブックで事前にトレーニングされていること\r\n",
    "2. このノートブックは、前提 1 でノートブックを実行するために使用されたものと同様に、 Azure Databricks ワークスペースで実行すること\r\n",
    "3. (MML Spark と reco_utils が両方ともインストールされている)運用化のために準備された Databricks クラスタを使用すること\r\n",
    "  - 詳細については、[セットアップ](../../SETUP.md) の手順を参照\r\n",
    "4. Azure Machine Learning ワークスペースは、モデルトのレーニングに使用される Azure Databricks ワークスペースと同じリージョンにセットアップされていること\r\n",
    "  - 詳細については、[ワークスペースの作成](https://docs.microsoft.com/en-us/azure/machine-learning/service/setup-create-workspace)を参照\r\n",
    "5. Azure ML ワークスペース config.json が、Databricks では `dbfs:/aml_config/config.json` にアップロードされていること\r\n",
    "  - [環境の構成](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-environment)および[Databricks CLI](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html#access-dbfs-with-the-databricks-cli)を参照\r\n",
    "6. Azure Container Instance (ACI) が使用中の Azure サブスクリプションにされていること\r\n",
    "  - 詳細については、[サポートされているサービス](https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-manager-supported-services#portal)を参照"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スコア サービスのステップ\r\n",
    "この例では、\"スコアリング サービス\" は、docker コンテナーによって実行されるファンクションです。JSON 書式のペイロードを使用して POST 要求を受け取り、事前に推定されたモデルに基づいてスコアを生成します。この例では、数値とカテゴリの一連のフィーチャーに基づいてユーザー アイテムの相互作用の確率を予測する、事前に推定したモデルを使用します。そのモデルは PySpark を使用してトレーニングされているため、[MML Spark 提供](https://github.com/Azure/mmlspark/blob/master/docs/mmlspark-serving.md) を使用してモデルを実行する単一インスタンス(Dcoker コンテナ内)にSparkセッションを作成します。受信した入力データに対して、相互作用の確率を返します。Azure Machine Learning を使用して、Docker コンテナーを作成して実行します。\r\n",
    "\r\n",
    "スコアリング サービスを作成するには、次の手順を実行します：\r\n",
    "\r\n",
    "1. Azure Machine Learning ワークスペースのセットアップと認証\r\n",
    "2. 以前にトレーニングされたモデルをシリアル化し、Azure モデル 登録に追加する\r\n",
    "3. モデルを実行する 'スコアリング サービス' スクリプトを定義する\r\n",
    "4. スクリプトに必要なすべての前提条件を定義する\r\n",
    "5. モデル、ドライバー スクリプト、および前提条件を使用して Azure コンテナ イメージを作成する\r\n",
    "6. スケーラブルなプラットフォームである Azure Kubernetes サービスにコンテナ イメージをデプロイする\r\n",
    "7. サービスのテスト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリと変数のセットアップ\r\n",
    "\r\n",
    "以下のいくつかのセルは、環境と変数を初期化します: ここで関連するライブラリをインポートし、変数を設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK version: 1.0.18\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "import json\r\n",
    "import shutil\r\n",
    "\r\n",
    "from reco_utils.dataset.criteo import get_spark_schema, load_spark_df\r\n",
    "from reco_utils.azureml.aks_utils import qps_to_replicas, replicas_to_qps, nodes_to_replicas\r\n",
    "\r\n",
    "from azureml.core import Workspace\r\n",
    "from azureml.core import VERSION as azureml_version\r\n",
    "\r\n",
    "from azureml.core.model import Model\r\n",
    "from azureml.core.conda_dependencies import CondaDependencies \r\n",
    "from azureml.core.webservice import Webservice, AksWebservice\r\n",
    "from azureml.core.image import ContainerImage\r\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\r\n",
    "\r\n",
    "from math import floor\r\n",
    "\r\n",
    "# コア SDK バージョン番号の確認\r\n",
    "print(\"Azure ML SDK version: {}\".format(azureml_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スコアリング サービス 変数の構成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'lightgbm_criteo.mml'  # この名前は、推論用ノートブックにパイプライン モデルを保存するために使用される名前と完全に一致する必要があります\r\n",
    "MODEL_DESCRIPTION = 'LightGBM Criteo Model'\r\n",
    "\r\n",
    "# AzureML アセットのセットアップ (名前はスペースを使用しない小文字の英数字で、3 ～ 32 文字の間でなければなりません)\r\n",
    "# Azure ML Web サービス\r\n",
    "SERVICE_NAME = 'lightgbm-criteo'\r\n",
    "# Azure ML コンテナ イメージ\r\n",
    "CONTAINER_NAME = SERVICE_NAME\r\n",
    "CONTAINER_RUN_TIME = 'spark-PY'\r\n",
    "# Azure Kubernetes Service (AKS)\r\n",
    "AKS_NAME = 'predict-aks'\r\n",
    "\r\n",
    "# 使用するその他のファイルの名前\r\n",
    "CONDA_FILE = \"deploy_conda.yaml\"\r\n",
    "DRIVER_FILE = \"mmlspark_serving.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AzureML ワークスペースのセットアップ\r\n",
    "ワークスペース構成は、ポータルから取得し、Databricks にアップロードできます<br>\r\n",
    "[AzureML on Databricks](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-environment#azure-databricks)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config('/dbfs/aml_config/config.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シリアル化されたモデルを準備する\r\n",
    "\r\n",
    "docker コンテナを作成するには、最初に作成する docker コンテナーがアクセスできるように、前の手順で推定したモデルを準備します。これを行うには、モデルをワークスペースに 登録します (詳細については、[Azure ML ドキュメント](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-model-management-and-deployment)を参照してください)。\r\n",
    "\r\n",
    "モデルは dbfs のディレクトリとして保存されており、登録する前にプロセスを容易にするためにいくつかの追加手順を実行します。\r\n",
    "\r\n",
    "### 入力スキーマ\r\n",
    "\r\n",
    "Spark サービングには、生の入力データのスキーマが必要です。したがってスキーマを取得し、モデル ディレクトリに追加のファイルとして格納します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_schema = get_spark_schema()\n",
    "with open(os.path.join('/dbfs', MODEL_NAME, 'schema.json'), 'w') as f:\n",
    "  f.write(raw_schema.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dbfs からローカルにモデルをコピーする\r\n",
    "\r\n",
    "ローカル ファイル API を使用して DBFS 上のファイルにアクセスできますが、ローカル ファイル API は 2 GB 未満のファイルにのみアクセスできるため、dbfs との間で保存されたモデルを明示的にコピーする方が安全です (詳細は[こちら](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html#access-dbfs-using-local-file-apis)を参照してください)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>True\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_local = os.path.join(os.getcwd(), MODEL_NAME)\n",
    "dbutils.fs.cp('dbfs:/' + MODEL_NAME, 'file:' + model_local, recurse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの登録\r\n",
    "\r\n",
    "これで、Azure Machine Learning ワークスペースにモデルを登録する準備ができました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Registering model lightgbm_criteo.mml\n",
       "lightgbm_criteo.mml LightGBM Criteo Model 4\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# まずデータ転送を最小限に抑えるためにモデル ディレクトリを圧縮します\r\n",
    "zip_file = shutil.make_archive(base_name=MODEL_NAME, format='zip', root_dir=model_local)\r\n",
    "\r\n",
    "# モデルの登録\r\n",
    "model = Model.register(model_path=zip_file,  # ここではローカル ファイルをポイントします\r\n",
    "                       model_name=MODEL_NAME,  # これはモデルの登録名です\r\n",
    "                       description=MODEL_DESCRIPTION,\r\n",
    "                       workspace=ws)\r\n",
    "\r\n",
    "print(model.name, model.description, model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スコアリング スクリプトの定義\r\n",
    "\r\n",
    "次に、サービスが呼び出されたときに実行されるドライバー スクリプトを作成する必要があります。スコアリングのために定義する必要がある関数は `init()` と `run()` です。`init()` 関数は、サービスの作成時に実行され、サービスが呼び出されるたびに `run()` 関数が実行されます。\r\n",
    "\r\n",
    "この例では、`init()` 関数を使用してすべてのライブラリを読み込み、Spark セッションを初期化し、Spark ストリーミング サービスを開始し、モデル パイプラインを読み込みます。`run()` メソッドを使用して入力を Spark ストリーミング サービスにルーティングし、予測 (この場合はインタラクションの確率) を生成し、出力を返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "driver_file = '''\r\n",
    "import os\r\n",
    "import json\r\n",
    "from time import sleep\r\n",
    "from uuid import uuid4\r\n",
    "from zipfile import ZipFile\r\n",
    "\r\n",
    "from azureml.core.model import Model\r\n",
    "from pyspark.ml import PipelineModel\r\n",
    "from pyspark.sql import SparkSession\r\n",
    "from pyspark.sql.types import StructType\r\n",
    "import requests\r\n",
    "\r\n",
    "\r\n",
    "def init():\r\n",
    "    \"\"\"One time initialization of pyspark and model server\"\"\"\r\n",
    "\r\n",
    "    spark = SparkSession.builder.appName(\"Model Server\").getOrCreate()\r\n",
    "    import mmlspark  # this is needed to load mmlspark libraries\r\n",
    "\r\n",
    "    # extract and load model\r\n",
    "    model_path = Model.get_model_path('{model_name}')\r\n",
    "    with ZipFile(model_path, 'r') as f:\r\n",
    "        f.extractall('model')\r\n",
    "    model = PipelineModel.load('model')\r\n",
    "\r\n",
    "    # load data schema saved with model\r\n",
    "    with open(os.path.join('model', 'schema.json'), 'r') as f:\r\n",
    "        schema = StructType.fromJson(json.load(f))\r\n",
    "\r\n",
    "    input_df = (\r\n",
    "        spark.readStream.continuousServer()\r\n",
    "        .address(\"localhost\", 8089, \"predict\")\r\n",
    "        .load()\r\n",
    "        .parseRequest(schema)\r\n",
    "    )\r\n",
    "\r\n",
    "    output_df = (\r\n",
    "        model.transform(input_df)\r\n",
    "        .makeReply(\"probability\")\r\n",
    "    )\r\n",
    "\r\n",
    "    checkpoint = os.path.join('/tmp', 'checkpoints', uuid4().hex)\r\n",
    "    server = (\r\n",
    "        output_df.writeStream.continuousServer()\r\n",
    "        .trigger(continuous=\"30 seconds\")\r\n",
    "        .replyTo(\"predict\")\r\n",
    "        .queryName(\"prediction\")\r\n",
    "        .option(\"checkpointLocation\", checkpoint)\r\n",
    "        .start()\r\n",
    "    )\r\n",
    "\r\n",
    "    # let the server finish starting\r\n",
    "    sleep(1)\r\n",
    "\r\n",
    "\r\n",
    "def run(input_json):\r\n",
    "    try:\r\n",
    "        response = requests.post(data=input_json, url='http://localhost:8089/predict')\r\n",
    "        result = response.json()['probability']['values'][1]\r\n",
    "    except Exception as e:\r\n",
    "        result = str(e)\r\n",
    "    \r\n",
    "    return json.dumps({{\"result\": result}})\r\n",
    "    \r\n",
    "'''.format(model_name=MODEL_NAME)\r\n",
    "\r\n",
    "# 文法のチェック\r\n",
    "exec(driver_file)\r\n",
    "\r\n",
    "with open(DRIVER_FILE, \"w\") as f:\r\n",
    "    f.write(driver_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 依存関係の定義\r\n",
    "\r\n",
    "次に、ドライバー スクリプトで必要な依存関係を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# azureml-sdk は登録されたモデルを読み込むために必要です\r\n",
    "conda_file = CondaDependencies.create(pip_packages=['azureml-sdk', 'requests']).serialize_to_string()\r\n",
    "\r\n",
    "with open(CONDA_FILE, \"w\") as f:\r\n",
    "    f.write(conda_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## イメージを作成する\r\n",
    "\r\n",
    "`ContainerImage` クラスを使用して、最初に定義されたドライバーと依存関係を使用してイメージを構成し、次に後で使用するイメージを作成します。\r\n",
    "イメージをビルドすると、Docker を使用してローカルにダウンロードおよびデバッグすることができます。[トラブルシューティング方法](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-troubleshoot-deployment)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Creating image\n",
       "Running......................\n",
       "SucceededImage creation operation finished for image lightgbm-criteo:3, operation &quot;Succeeded&quot;\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_config = ContainerImage.image_configuration(execution_script=DRIVER_FILE, \n",
    "                                                  runtime=CONTAINER_RUN_TIME,\n",
    "                                                  conda_file=CONDA_FILE,\n",
    "                                                  tags={\"runtime\":CONTAINER_RUN_TIME, \"model\": MODEL_NAME})\n",
    "\n",
    "image = ContainerImage.create(name=CONTAINER_NAME,\n",
    "                              models=[model],\n",
    "                              image_config=image_config,\n",
    "                              workspace=ws)\n",
    "\n",
    "image.wait_for_creation(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## サービスの作成\r\n",
    "\r\n",
    "イメージを作成したら、Azure Kubernetes サービス (AKS) を構成し、イメージを AKS Web Service としてデプロイします。\r\n",
    "\r\n",
    "**注** 私たちは `Webservice.deploy_from_model()` ファンクションを使用して、登録されたモデルとimage_configuration から直接サービスを作成することが可能です。ここではイメージを明示的に作成し、次の 3 つの理由から `deploy_from_image()` を使用します:\r\n",
    "\r\n",
    "1. 実際に行われているステップの面でより透明性を提供します。\r\n",
    "2. これにより多くの柔軟性および制御を提供します。たとえば、作成するサービスとは無関係な名前のイメージを作成できます。これは、イメージを複数のサービスで使用する場合に役立ちます。\r\n",
    "3. これにより、潜在的により速い反復およびより多くの移植性を得られます。イメージが作成されると、まったく同じコードで新しいデプロイを作成することができます。\r\n",
    "\r\n",
    "### セットアップと計画\r\n",
    "\r\n",
    "本番サービスを設定する際には、まずサポートする負荷量を見積もる必要があります。それを見積るためには、1 回の呼び出しにかかる時間を見積もる必要があります。この例では、いくつかのローカル テストを行い、1 つのクエリの処理に約 100 ミリ秒掛かると見積もっています。\r\n",
    "\r\n",
    "いくつかの追加の仮定に基づいて、1 秒あたりの目標数のクエリ(qps) をサポートするために必要なレプリカの数を見積もることができます。\r\n",
    "\r\n",
    "**注**: この見積もりは開始点としての概算数として使用する必要があり、我々はより良い見積りにブラッシュアップするために、その後のロードテストでパフォーマンスを検証することができます。詳細については、こちらの[ドキュメント](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-deploy-and-where#aks)を参照してください。\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この種の計算をサポートするヘルパー関数をいくつか記述し、1 つのクエリを完了する時間の見積もりとして 100 ミリ秒を使用して、1 秒あたり 25、50、100、200、および 350 クエリの読み込みをサポートするために必要なレプリカの数を推定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_target_qps = [25, 50, 100, 200, 350]\r\n",
    "query_processing_time = 0.1  ## 処理/秒\r\n",
    "replica_estimates = {t: qps_to_replicas(t, query_processing_time) for t in all_target_qps}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "顧客ベースの規模やその他の考慮事項(トラフィックを増やす可能性のある今後の予定など)に基づいて、サポートする最大負荷を決定します。この例では、1 秒あたり 100 のクエリをサポートする必要があり、対応するレプリカの数 (上記の見積もりに基づいて 15 個) を使用する必要があることを示します。\r\n",
    "\r\n",
    "レプリカの数がわかったら、Azure Kubernetes サービス内に十分なリソース (コアとメモリ) があり、その数のレプリカをサポートする必要があります。その数を見積もるためには、各レプリカに割り当てられるコアの数を知る必要があります。コアごとに複数のレプリカがあるユース ケースが多いため、この数は小数点数になる可能性があります。詳細は[こちら](https://kubernetes.io/docs/tasks/configure-pod-container/assign-cpu-resource/#cpu-units)をご覧ください。以下の Web サービスを作成するときは、各レプリカに 0.3 の `cpu_cores` と 0.5 GB のメモリを割り当てます。15 のレプリカをサポートするには、`15*0.3` コアと `15*0.5 GB` のメモリが必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5 cores required\n",
      "7.5 GB of memory required\n"
     ]
    }
   ],
   "source": [
    "cpu_cores_per_replica = 0.3\n",
    "print('{} cores required'.format(replica_estimates[100]*cpu_cores_per_replica))\n",
    "print('{} GB of memory required'.format(replica_estimates[100]*0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure Kubernetes サービスをプロビジョニングする\r\n",
    "\r\n",
    "必要なコア数とメモリ量の見積もりができたので、AKS クラスターを構成して作成します。デフォルトでは、`AksCompute.provisioning_configuration()` は `vm_size='Standard_D3_v2'` を持つ 3 つのエージェントを持つ構成を作成します。各 Standard_D3_v2 仮想マシンには 4 つのコアと 14 GB のメモリがあるので、デフォルトでは 12 コアと 42 GB のメモリを組み合わせたクラスタが作成され、推定負荷要件を満たすのに十分です。\r\n",
    "\r\n",
    "**注**: この特定のケースでは、負荷要件が 4.5 コアに過ぎない場合でも、AKS クラスターの 12 コアを下回 らない 必要があります。12 コアは、Web サービスに必要な AKS のコアの最小数です。[詳細](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-deploy-and-where#aks)については、ドキュメントを参照してください。`agent_count` パラメーターと `vm_size` パラメーターを使用して、負荷要件で必要な場合はコア数を 12 を超える値を増やすことができますが、それらを使用して減らすことはしないでください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最初に AKS コンピュートを作成\r\n",
    "\r\n",
    "# 既定の構成を使用する (カスタマイズするパラメーターを提供することもできます)\r\n",
    "prov_config = AksCompute.provisioning_configuration()\r\n",
    "\r\n",
    "# クラスタの作成\r\n",
    "aks_target = ComputeTarget.create(\r\n",
    "  workspace=ws, \r\n",
    "  name=AKS_NAME, \r\n",
    "  provisioning_configuration=prov_config\r\n",
    ")\r\n",
    "\r\n",
    "aks_target.wait_for_completion(show_output=True)\r\n",
    "\r\n",
    "print(aks_target.provisioning_state)\r\n",
    "print(aks_target.provisioning_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検討事項\r\n",
    "\r\n",
    "推定される負荷要件は Azure Machine Learning によって設定された最小値より小さいため、Web サービスで使用するレプリカの数を見積もる別の方法を検討する必要があります。これが AKS クラスターで実行される唯一のサービスである場合、すべてのコンピューティング リソースを活用しないことでリソースを浪費している可能性があります。最初は、予想される負荷を使用して、使用するレプリカの数を見積もります。このアプローチの代わりに、クラスター内のコア数を使用して、サポートできるレプリカの最大数を推定することもできます。\r\n",
    "\r\n",
    "レプリカの最大数を見積もるためには、ベースとなる kubernetes の操作とノードのオペレーティング システムとコア機能の各ノードにオーバーヘッドがあることを考慮する必要があります。この場合は 10\\% のオーバーヘッドを想定していますが、詳細については[こちら](https://docs.microsoft.com/en-us/azure/aks/concepts-clusters-workloads)を参照してください。\r\n",
    "\r\n",
    "**注** この例ではコアを使用していますが、代わりにメモリ要件を活用することもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_replicas_12_cores = nodes_to_replicas(\n",
    "    n_cores_per_node=4, n_nodes=3, cpu_cores_per_replica=cpu_cores_per_replica\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クラスターがサポートするレプリカの数が判明すると、AKS クラスタがサポートできると考えられる 1 秒あたりのクエリを推定できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicas_to_qps(max_replicas_12_cores, query_processing_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web サービスを作成する\r\n",
    "\r\n",
    "次に、Web サービスを構成して作成します。この構成では、各レプリカが `cpu_cores=cpu_cores_per_replica` (デフォルトは `cpu_cores=0.1`) を設定するとします。この値はこのサービスの経験と事前のテストに基づいて調整しています。\r\n",
    "\r\n",
    "`AksWebservice.deploy_configuration()` に引数が渡されない場合は、`autoscale_enabled=True` と共に `autoscale_min_replicas=1` と `autoscale_max_replicas=10` が設定されます。最大値は、1 秒あたり 100 クエリをサポートするための最小要件を満たしていないため、調整する必要があります。この値は、負荷 (15) に基づいて見積もりを調整するか、AKS クラスター (36) でサポートできる数に基づいて見積もりを調整できます。この例では、AKS クラスターを他のタスクまたはサービスに使用できるように、負荷に基づく値に設定します。\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "webservice_config = AksWebservice.deploy_configuration(cpu_cores=cpu_cores_per_replica,\r\n",
    "                                                       autoscale_enabled=True,\r\n",
    "                                                       autoscale_max_replicas=replica_estimates[100])\r\n",
    "\r\n",
    "# 作成したイメージを使用してサービスを展開する\r\n",
    "aks_service = Webservice.deploy_from_image(\r\n",
    "  workspace=ws, \r\n",
    "  name=SERVICE_NAME,\r\n",
    "  deployment_config=webservice_config,\r\n",
    "  image=image,\r\n",
    "  deployment_target=aks_target\r\n",
    ")\r\n",
    "\r\n",
    "aks_service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## サービスをテストする\r\n",
    "\r\n",
    "次に、`sample` データのデータを使用してサービスをテストできます。\r\n",
    "\r\n",
    "このサービスは JSON をペイロードとして想定しているので、サンプル データを取得し、ディクショナリに変換してからサービス エンドポイントに送信します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URI を表示\r\n",
    "url = aks_service.scoring_uri\r\n",
    "print('AKS URI: {}'.format(url))\r\n",
    "\r\n",
    "# aks_service のキーのいずれかを使用した認証のセットアップ\r\n",
    "headers = dict(Authorization='Bearer {}'.format(aks_service.get_keys()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# いくつかのサンプルデータを使用\r\n",
    "df = load_spark_df(size='sample', spark=spark, dbutils=dbutils)\r\n",
    "data = df.head().asDict()\r\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AKS クラスターに要求を送信\r\n",
    "response = requests.post(url=url, json=data, headers=headers)\r\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### サービスを削除する\r\n",
    "\r\n",
    "全てが完了後、コストを最小限に抑えるためにサービスを削除できます。上記の同じコマンドを使用して、イメージからいつでも再デプロイできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Web サービスを削除するには、次の行のコメントを解除します\r\n",
    "# aks_service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">34</span><span class=\"ansired\">]: </span>&apos;Deleting&apos;\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aks_service.state"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "pasha"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('vscpy38': conda)",
   "name": "python385jvsc74a57bd0be443e4bb5ca2a0039df422708907d2b33984b7dfb9ef6e469c27513aa2f1c12"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "be443e4bb5ca2a0039df422708907d2b33984b7dfb9ef6e469c27513aa2f1c12"
   }
  },
  "name": "deploy-to-aci-04",
  "notebookId": 904892461294324
 },
 "nbformat": 4,
 "nbformat_minor": 1
}