{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# リアルタイム レコメンデーション API 環境を構築する\r\n",
    "\r\n",
    "このリファレンス アーキテクチャは、レコメンデーションシステム構築の完全なライフ サイクルを示しています。このシナリオでは、Azure Databricks を使用して、API として展開するレコメンデーション モデルのトレーニング、適切な Azure リソースの作成を説明します。Azure Cosmos DB、Azure Machine Learning と Azure Kubernetes Service を使用します。\r\n",
    "\r\n",
    "このアーキテクチャは、製品、映画・番組、およびニュースのレコメンデーションを含む多くの一般的なレコメンデーション エンジン シナリオに適用することができます。\r\n",
    "### アーキテクチャ\r\n",
    "![architecture](https://recodatasets.z20.web.core.windows.net/images/reco-arch.png \"Architecture\")\r\n",
    "\r\n",
    "**シナリオ**: とあるメディア企業は、自社のユーザーに映画やビデオのレコメンデーションを提供したいと考えています。パーソナライズされたレコメンデーションを提供することによって、クリックスルー率やサイトの利用率、ユーザー満足度の高い増加を通じて、いくつかのビジネス目標を満たそうとしています。\r\n",
    "\r\n",
    "このリファレンスでは、訓練し、特定のユーザーに対してトップ 10 のレコメンドする映画を提供することが可能なリアルタイムのレコメンデーション サービス API をトレーニングし、展開します。\r\n",
    "\r\n",
    "### コンポーネント\r\n",
    "このアーキテクチャには、以下の主要なコンポーネントが含まれます:\r\n",
    "* [Azure Databricks](https://docs.microsoft.com/ja-jp/azure/azure-databricks/what-is-azure-databricks)<sup>1)</sup> は、入力データの準備と、Spark クラスター上でレコメンデーション モデルのトレーニング開発環境として使用されます。Azure Databricks はまた、データの処理や機械学習のタスクを実行するためのノートブックで共同作業を行うためのインタラクティブなワークスペースを提供します。\r\n",
    "* [Azure Kubernetes Service](https://docs.microsoft.com/ja-jp/azure/aks/intro-kubernetes)(AKS) は、Kubernetes クラスター上に機械学習モデルサービス API の展開と運用を行うために使用されます。AKS は、コンテナー化されたモデルをホストし、スループット要件を満たすためのスケーラビリティ、ID およびアクセスの管理、ログおよび状態監視を提供します。\r\n",
    "* [Azure Cosmos DB](https://docs.microsoft.com/ja-jp/azure/cosmos-db/introduction) は、ユーザーごとにレコメンドされた映画のトップ 10 を格納するために使用される、グローバル分散型データベース サービスです。Azure Cosmos DB は指定されたユーザーのトップ 10 のレコメンド アイテムの読み取りに対して低レイテンシ (99 パーセンタイルにおいて 10 ms) で提供可能なため、このシナリオに最適です。\r\n",
    "* [Azure Machine Learning](https://docs.microsoft.com/ja-jp/azure/machine-learning/) は、機械学習モデルのトラッキングと管理、スケーラブルな Azure Kubernetes Service環境にこれらのモデルをパッケージ化、展開するために使用するサービスです。\r\n",
    "\r\n",
    "<sup>1) ここでは、Azure Databricks の使用例を示します。[SETUP](../../SETUP.md) にリストされているプラットフォームは、いずれも使用できます。</sup>\r\n",
    "\r\n",
    "\r\n",
    "### 目次\r\n",
    "0. [ファイルのインポート](#0-File-Imports)\r\n",
    "1. [サービスの作成](#1-Service-Creation)\r\n",
    "2. [トレーニング](#2-Training)\r\n",
    "3. [運用化](#3.-Operationalize-the-Recommender-Service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## セットアップ\r\n",
    "Azure Databricks でこのノートブックを実行するには、リポジトリの[セットアップ手順](../../SETUP.md)の該当するセクションに従って Azure Databricks をセットアップし、このノートブックを Azure Databricks ワークスペースにインポートする必要があります ([こちら](https://docs.azuredatabricks.net/user-guide/notebooks/notebook-manage.html#import-a-notebook)の手順を参照してください)。\r\n",
    "\r\n",
    "注意: このノートブックでは、**運用化** をサポートするために依存関係を追加する **必要** があります。詳細については、[SETUP](../../SETUP.md) を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 ファイルのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure SDK version: 1.0.69\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import urllib\n",
    "\n",
    "from azure.common.client_factory import get_client_from_cli_profile\n",
    "import azure.mgmt.cosmosdb\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "from azureml.core import Environment\n",
    "from azureml.core.environment import CondaDependencies\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import SparkPackage\n",
    "import pydocumentdb.document_client as document_client\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import FloatType, IntegerType, LongType\n",
    "\n",
    "from reco_utils.common.timer import Timer\n",
    "from reco_utils.common.spark_utils import start_or_get_spark\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.cosmos_cli import find_collection, read_collection, read_database, find_database\n",
    "from reco_utils.dataset.download_utils import maybe_download\n",
    "from reco_utils.dataset.spark_splitters import spark_random_split\n",
    "from reco_utils.evaluation.spark_evaluation import SparkRatingEvaluation, SparkRankingEvaluation\n",
    "from reco_utils.common.notebook_utils import is_databricks\n",
    "\n",
    "print(\"Azure SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.99.107:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ALS</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=ALS>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 必要に応じて Spark セッションを開始する\r\n",
    "if not is_databricks():\r\n",
    "    cosmos_connector = (\r\n",
    "        \"https://search.maven.org/remotecontent?filepath=com/microsoft/azure/\"\r\n",
    "        \"azure-cosmosdb-spark_2.3.0_2.11/1.3.3/azure-cosmosdb-spark_2.3.0_2.11-1.3.3-uber.jar\"\r\n",
    "    )\r\n",
    "    jar_filepath = maybe_download(url=cosmos_connector, filename=\"cosmos.jar\")\r\n",
    "    spark = start_or_get_spark(\"ALS\", memory=\"10g\", jars=[jar_filepath])\r\n",
    "    sc = spark.sparkContext\r\n",
    "display(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 サービスの作成\r\n",
    "デプロイするサブスクリプションに対して **サブスクリプション ID** を変更し、リソース名変数を設定します。\r\n",
    "\r\n",
    "#### このノートブックで作成されるサービス:\r\n",
    "1. [Azure ML Service](https://azure.microsoft.com/ja-jp/services/machine-learning-service/)\r\n",
    "    1. [Azure ML Workspace](https://docs.microsoft.com/ja-jp/azure/machine-learning/concept-workspace)\r\n",
    "    1. [Azure Application Insights](https://azure.microsoft.com/ja-jp/services/monitor/)\r\n",
    "    1. [Azure Storage](https://docs.microsoft.com/ja-jp/azure/storage/common/storage-account-overview)\r\n",
    "    1. [Azure Key Vault](https://azure.microsoft.com/ja-jp/services/key-vault/)    \r\n",
    "\r\n",
    "1. [Azure Cosmos DB](https://azure.microsoft.com/ja-jp/services/cosmos-db/)\r\n",
    "1. [Azure Kubernetes Service (AKS)](https://azure.microsoft.com/ja-jp/services/kubernetes-service/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**自分のサブスクリプション ID を追加**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自分のサブスクリプション ID を追加\r\n",
    "subscription_id = \"\"\r\n",
    "\r\n",
    "# ワークスペース名をセットする\r\n",
    "workspace_name = \"o16n-test\"\r\n",
    "resource_group = \"{}-rg\".format(workspace_name)\r\n",
    "\r\n",
    "# Azure ML ワークスペースを自分のリージョンをセットする\r\n",
    "location = \"eastus\"\r\n",
    "\r\n",
    "# AzureML と Azure Kubernetes Service のプリフィックスを指定する\r\n",
    "service_name = \"mvl-als\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AzureML が Azure CLI ログイン資格情報を使用できるように、Azure CLI にログインします。\r\n",
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要に応じてサブスクリプションを変更する\r\n",
    "!az account set --subscription {subscription_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アカウントのチェック\r\n",
    "!az account show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CosmosDB\r\n",
    "# CosmosDB のaccount_nameは '_' を使用できず、31 文字未満である必要があります\r\n",
    "account_name = \"{}-ds-sql\".format(workspace_name).replace(\"_\", \"-\")[:31]\r\n",
    "cosmos_database = \"recommendations\"\r\n",
    "cosmos_collection = \"user_recommendations_als\"\r\n",
    "\r\n",
    "# AzureML リソース名\r\n",
    "model_name = \"{}-reco.mml\".format(service_name)\r\n",
    "aks_name = \"{}-aks\".format(service_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レコメンドする上位 k 個の項目\r\n",
    "TOP_K = 10\r\n",
    "\r\n",
    "# MovieLens のデータサイズを選択します: 100k, 1m, 10m, or 20m\r\n",
    "MOVIELENS_DATA_SIZE = '100k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "userCol = \"UserId\"\n",
    "itemCol = \"MovieId\"\n",
    "ratingCol = \"Rating\"\n",
    "\n",
    "train_data_path = \"train\"\n",
    "test_data_path = \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 インポートまたは AzureML ワークスペースの作成\r\n",
    "このコマンドは、AzureML ワークスペースが存在するかどうかを確認し、存在しない場合はワークスペースを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ws = Workspace.create(\n",
    "    name=workspace_name,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group=resource_group, \n",
    "    location=location,\n",
    "    exist_ok=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 レコメンデーション結果を保存する Cosmos DB を作成する\r\n",
    "\r\n",
    "この手順でCosmosDB リソースを作成するには、多少時間がかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database created\n",
      "Collection created\n"
     ]
    }
   ],
   "source": [
    "# ユーザーが複数のサブスクリプションを持っている場合に、明示的に subscription_id を渡す\r\n",
    "client = get_client_from_cli_profile(\r\n",
    "    azure.mgmt.cosmosdb.CosmosDB,\r\n",
    "    subscription_id=subscription_id\r\n",
    ")\r\n",
    "\r\n",
    "async_cosmosdb_create = client.database_accounts.create_or_update(\r\n",
    "    resource_group,\r\n",
    "    account_name,\r\n",
    "    {\r\n",
    "        'location': location,\r\n",
    "        'locations': [{\r\n",
    "            'location_name': location\r\n",
    "        }]\r\n",
    "    }\r\n",
    ")\r\n",
    "account = async_cosmosdb_create.result()\r\n",
    "\r\n",
    "my_keys = client.database_accounts.list_keys(resource_group, account_name)\r\n",
    "master_key = my_keys.primary_master_key\r\n",
    "endpoint = \"https://\" + account_name + \".documents.azure.com:443/\"\r\n",
    "\r\n",
    "# DB クライアント\r\n",
    "client = document_client.DocumentClient(endpoint, {'masterKey': master_key})\r\n",
    "\r\n",
    "if not find_database(client, cosmos_database):\r\n",
    "    db = client.CreateDatabase({'id': cosmos_database })\r\n",
    "    print(\"Database created\")\r\n",
    "else:\r\n",
    "    db = read_database(client, cosmos_database)\r\n",
    "    print(\"Database found\")\r\n",
    "\r\n",
    "# コレクション オプション の作成\r\n",
    "options = dict(offerThroughput=11000)\r\n",
    "\r\n",
    "# コレクションの作成\r\n",
    "collection_definition = {\r\n",
    "    'id': cosmos_collection,\r\n",
    "    'partitionKey': {'paths': ['/id'],'kind': 'Hash'}\r\n",
    "}\r\n",
    "if not find_collection(client, cosmos_database, cosmos_collection):\r\n",
    "    collection = client.CreateCollection(\r\n",
    "        db['_self'], \r\n",
    "        collection_definition,\r\n",
    "        options\r\n",
    "    )\r\n",
    "    print(\"Collection created\")\r\n",
    "else:\r\n",
    "    collection = read_collection(client, cosmos_database, cosmos_collection)\r\n",
    "    print(\"Collection found\")\r\n",
    "    \r\n",
    "dbsecrets = dict(\r\n",
    "    Endpoint=endpoint, \r\n",
    "    Masterkey=master_key, \r\n",
    "    Database=cosmos_database, \r\n",
    "    Collection=cosmos_collection, \r\n",
    "    Upsert=True\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 トレーニング\r\n",
    "\r\n",
    "次に、[MovieLens](https://grouplens.org/datasets/movielens/) データセットで[最小二乗法モデル](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html)をトレーニングします。\r\n",
    "\r\n",
    "### 2.1 MovieLens データセットをダウンロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.81k/4.81k [00:00<00:00, 11.0kKB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|UserId|MovieId|Rating|\n",
      "+------+-------+------+\n",
      "|   196|    242|   3.0|\n",
      "|   186|    302|   3.0|\n",
      "|    22|    377|   1.0|\n",
      "|   244|     51|   2.0|\n",
      "|   166|    346|   1.0|\n",
      "|   298|    474|   4.0|\n",
      "|   115|    265|   2.0|\n",
      "|   253|    465|   5.0|\n",
      "|   305|    451|   3.0|\n",
      "|     6|     86|   3.0|\n",
      "|    62|    257|   2.0|\n",
      "|   286|   1014|   5.0|\n",
      "|   200|    222|   5.0|\n",
      "|   210|     40|   3.0|\n",
      "|   224|     29|   3.0|\n",
      "|   303|    785|   3.0|\n",
      "|   122|    387|   5.0|\n",
      "|   194|    274|   2.0|\n",
      "|   291|   1042|   4.0|\n",
      "|   234|   1184|   2.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 注: ALS 用のデータフレーム ベースの API は、現在、ユーザー ID とアイテム ID の整数のみをサポートしています。\r\n",
    "schema = StructType(\r\n",
    "    (\r\n",
    "        StructField(userCol, IntegerType()),\r\n",
    "        StructField(itemCol, IntegerType()),\r\n",
    "        StructField(ratingCol, FloatType()),\r\n",
    "    )\r\n",
    ")\r\n",
    "\r\n",
    "data = movielens.load_spark_df(spark, size=MOVIELENS_DATA_SIZE, schema=schema)\r\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 データをトレーニングとテスト用に分割する\r\n",
    "データを分割する方法は、ランダム、時系列、階層化など、それぞれが異なる実世界の評価のユースケースを優先する方法です。この例ではランダムに分割します – どのスプリッタを選択するかの詳細については、[このガイド](../01_prepare_data/data_split.ipynb)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N train 75031\n",
      "N test 24969\n"
     ]
    }
   ],
   "source": [
    "train, test = spark_random_split(data, ratio=0.75, seed=42)\n",
    "print(\"N train\", train.cache().count())\n",
    "print(\"N test\", test.cache().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 トレーニング データを使って ALS モデルをトレーニングする\r\n",
    "\r\n",
    "映画の評価を予測するには、トレーニングセットの評価データをユーザーの明示的なフィードバックとして使用します。モデルの推定に使用されるハイパーパラメーターは、[このページ](http://mymedialite.net/examples/datasets.html)に基づいて設定されます。ほとんどの場合、ハイパーパラメーターを調べ、いくつかの基準に基づいて最適なセットを選択します。このプロセスの詳細については、詳細については、[こちら](../04_model_select_and_optimize/tuning_spark_als.ipynb)の詳細をご覧ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(\n",
    "    rank=10,\n",
    "    maxIter=15,\n",
    "    implicitPrefs=False,\n",
    "    alpha=0.1,\n",
    "    regParam=0.05,\n",
    "    coldStartStrategy='drop',\n",
    "    nonnegative=True,\n",
    "    userCol=userCol,\n",
    "    itemCol=itemCol,\n",
    "    ratingCol=ratingCol,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 テストデータを利用してトップK個のレコメンデーションを取得する\r\n",
    "\r\n",
    "映画おすすめのユースケースでは、ユーザーが評価したおすすめ映画は意味を成しません。したがって、評価された動画はレコメンデーション項目から削除されます。\r\n",
    "\r\n",
    "これを実現するために、すべてのユーザーにすべてのムービーを推奨し、トレーニング データセットに存在するユーザーとムービーのペアを削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "|UserId|MovieId|prediction|\n",
      "+------+-------+----------+\n",
      "|   148|    148| 2.2560365|\n",
      "|   463|    148|  2.936453|\n",
      "|   471|    148| 3.8262048|\n",
      "|   496|    148| 2.2901149|\n",
      "|   833|    148| 1.7296925|\n",
      "|   243|    148| 2.2667758|\n",
      "|   392|    148| 2.4605818|\n",
      "|   540|    148| 3.0631547|\n",
      "|   623|    148| 3.1649487|\n",
      "|   737|    148| 1.7344649|\n",
      "|   858|    148| 1.8472893|\n",
      "|   897|    148| 3.5229573|\n",
      "|    31|    148| 1.9613894|\n",
      "|   516|    148| 3.1411705|\n",
      "|    85|    148| 2.2291098|\n",
      "|   137|    148| 4.0498815|\n",
      "|   251|    148| 3.2075853|\n",
      "|   451|    148|  4.016654|\n",
      "|   580|    148|  2.843738|\n",
      "|   808|    148| 3.4666717|\n",
      "+------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# すべてのユーザーと項目のペアのクロス結合を取得し、それらをスコア付けします。\r\n",
    "users = train.select(userCol).distinct()\r\n",
    "items = train.select(itemCol).distinct()\r\n",
    "user_item = users.crossJoin(items)\r\n",
    "dfs_pred = model.transform(user_item)\r\n",
    "dfs_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "|UserId|MovieId|prediction|\n",
      "+------+-------+----------+\n",
      "|     1|    587| 3.4595456|\n",
      "|     1|    869|  2.967618|\n",
      "|     1|   1208|  2.858056|\n",
      "|     1|   1677| 2.9235902|\n",
      "|     2|     80| 3.0129535|\n",
      "|     2|    303| 3.0719132|\n",
      "|     2|    472| 3.4143965|\n",
      "|     2|    582|  4.877232|\n",
      "|     2|    838|  1.529903|\n",
      "|     2|    975| 2.9654517|\n",
      "|     2|   1260|  3.252151|\n",
      "|     2|   1325| 1.1417896|\n",
      "|     2|   1381| 3.7900786|\n",
      "|     2|   1530|  2.625749|\n",
      "|     3|     22| 2.7082264|\n",
      "|     3|     57| 2.5156925|\n",
      "|     3|     89| 3.7927365|\n",
      "|     3|    367| 2.7083492|\n",
      "|     3|   1091| 1.5662774|\n",
      "|     3|   1167| 3.2427955|\n",
      "+------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 表示された項目を削除します。\r\n",
    "dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\r\n",
    "    train.alias(\"train\"),\r\n",
    "    (dfs_pred[userCol]==train[userCol]) & (dfs_pred[itemCol]==train[itemCol]),\r\n",
    "    how='outer'\r\n",
    ")\r\n",
    "top_all = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[\"train.\"+ratingCol].isNull()) \\\r\n",
    "    .select(\"pred.\"+userCol, \"pred.\"+itemCol, \"pred.prediction\")\r\n",
    "\r\n",
    "top_all.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 ALS のパフォーマンスを評価する\r\n",
    "\r\n",
    "Precision@K、Recall@K、[MAP@K](https://en.wikipedia.org/wiki/Evaluation_measures_\\(information_retrieval\\) 、[nDCG@K](https://en.wikipedia.org/wiki/Discounted_cumulative_gain)などのメトリックを使用して、モデルのパフォーマンスを評価します。推薦者を評価する指標の完全なガイドについては、[このガイド](../03_evaluate/evaluation.ipynb)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|UserId|MovieId|Rating|\n",
      "+------+-------+------+\n",
      "|     1|      2|   3.0|\n",
      "|     1|      3|   4.0|\n",
      "|     1|      4|   3.0|\n",
      "|     1|     14|   5.0|\n",
      "|     1|     17|   3.0|\n",
      "|     1|     27|   2.0|\n",
      "|     1|     29|   1.0|\n",
      "|     1|     35|   1.0|\n",
      "|     1|     36|   2.0|\n",
      "|     1|     51|   4.0|\n",
      "|     1|     52|   4.0|\n",
      "|     1|     54|   3.0|\n",
      "|     1|     56|   4.0|\n",
      "|     1|     60|   5.0|\n",
      "|     1|     64|   5.0|\n",
      "|     1|     69|   3.0|\n",
      "|     1|     77|   4.0|\n",
      "|     1|     83|   3.0|\n",
      "|     1|     85|   3.0|\n",
      "|     1|     88|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = {\n",
    "    'col_user': userCol,\n",
    "    'col_item': itemCol,\n",
    "    'col_rating': ratingCol,\n",
    "    'col_prediction': \"prediction\",\n",
    "}\n",
    "\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\tALS\n",
      "Top K:\t10\n",
      "MAP:\t0.003698\n",
      "NDCG:\t0.034331\n",
      "Precision@K:\t0.039343\n",
      "Recall@K:\t0.014976\n"
     ]
    }
   ],
   "source": [
    "# ランキング指標の評価\r\n",
    "rank_eval = SparkRankingEvaluation(\r\n",
    "    test, \r\n",
    "    top_all, \r\n",
    "    k=TOP_K,\r\n",
    "    **cols\r\n",
    ")\r\n",
    "\r\n",
    "print(\r\n",
    "    \"Model:\\tALS\",\r\n",
    "    \"Top K:\\t%d\" % rank_eval.k,\r\n",
    "    \"MAP:\\t%f\" % rank_eval.map_at_k(),\r\n",
    "    \"NDCG:\\t%f\" % rank_eval.ndcg_at_k(),\r\n",
    "    \"Precision@K:\\t%f\" % rank_eval.precision_at_k(),\r\n",
    "    \"Recall@K:\\t%f\" % rank_eval.recall_at_k(), sep='\\n'\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\tALS rating prediction\n",
      "RMSE:\t0.95\n",
      "MAE:\t0.740282\n",
      "Explained variance:\t0.289807\n",
      "R squared:\t0.285394\n"
     ]
    }
   ],
   "source": [
    "# ランキング指標の評価\r\n",
    "prediction = model.transform(test)\r\n",
    "rating_eval = SparkRatingEvaluation(\r\n",
    "    test, \r\n",
    "    prediction, \r\n",
    "    **cols\r\n",
    ")\r\n",
    "\r\n",
    "print(\r\n",
    "    \"Model:\\tALS rating prediction\",\r\n",
    "    \"RMSE:\\t%.2f\" % rating_eval.rmse(),\r\n",
    "    \"MAE:\\t%f\" % rating_eval.mae(),\r\n",
    "    \"Explained variance:\\t%f\" % rating_eval.exp_var(),\r\n",
    "    \"R squared:\\t%f\" % rating_eval.rsquared(), sep='\\n'\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 モデルを保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model\n",
    " .write()\n",
    " .overwrite()\n",
    " .save(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Recommender サービスの運用化\r\n",
    "モデルが望ましいパフォーマンスで構築されると、リアルタイム サービスで使用される REST エンドポイントとして実行するように運用が可能になります。[Azure Cosmos DB](https://azure.microsoft.com/ja-jp/services/cosmos-db/)、[Azure Machine Learning](https://azure.microsoft.com/ja-jp/services/machine-learning-service/)、および [Azure Kubernetes Service](https://docs.microsoft.com/ja-jp/azure/aks/intro-kubernetes)を利用して、レコメンデーション サービスを運用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Cosmos DB でレコメンデーションのルックアップを作成する\r\n",
    "\r\n",
    "まず、モデルで予測される各ユーザーの上位 10 件の推奨事項が、Cosmos DB にルックアップ テーブルとして格納されます。実行時に、サービスは、Cosmos DB に事前計算され、格納されたとして、Top-10 の推奨事項を返します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|             MovieId|\n",
      "+---+--------------------+\n",
      "|471|[745, 1540, 244, ...|\n",
      "|463|[64, 190, 1286, 3...|\n",
      "|833|[1192, 179, 1524,...|\n",
      "|496|[320, 1589, 262, ...|\n",
      "|148|[1512, 718, 793, ...|\n",
      "|540|[958, 1512, 1368,...|\n",
      "|392|[1643, 1449, 1512...|\n",
      "|243|[285, 251, 1405, ...|\n",
      "|623|[390, 1643, 173, ...|\n",
      "|737|[856, 60, 61, 151...|\n",
      "|897|[1368, 958, 320, ...|\n",
      "|858|[1154, 1129, 853,...|\n",
      "| 31|[1203, 1245, 889,...|\n",
      "|516|[745, 694, 1512, ...|\n",
      "|580|[1368, 958, 1589,...|\n",
      "|251|[1203, 1449, 253,...|\n",
      "|451|[1368, 1019, 958,...|\n",
      "| 85|[1643, 1449, 511,...|\n",
      "|137|[1368, 1643, 958,...|\n",
      "|808|[1512, 867, 1367,...|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recs = model.recommendForAllUsers(10)\n",
    "recs_topk = recs.withColumn(\"id\", recs[userCol].cast(\"string\")) \\\n",
    "    .select(\"id\", \"recommendations.\" + itemCol)\n",
    "recs_topk.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを Cosmos DB に保存\r\n",
    "(recs_topk.coalesce(1)\r\n",
    " .write\r\n",
    " .format(\"com.microsoft.azure.cosmosdb.spark\")\r\n",
    " .mode('overwrite')\r\n",
    " .options(**dbsecrets)\r\n",
    " .save())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Azure Azure Machine Learning の構成\r\n",
    "\r\n",
    "次に、Azure Machine Learning を使用して、モデル スコアリング イメージを作成し、スケーラブルなコンテナー化されたサービスとして Azure Kubernetes Service にデプロイします。これを実現するには、**スコアリング スクリプト** を作成する必要があります。スクリプトでは、Cosmos DB に呼び出しを行い、入力ユーザー ID を推奨する上位 10 の映画を検索します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sparkml = \"\"\"\r\n",
    "import json\r\n",
    "import pydocumentdb.document_client as document_client\r\n",
    "\r\n",
    "def init(local=False):\r\n",
    "    global client, collection\r\n",
    "    try:\r\n",
    "        client = document_client.DocumentClient('{endpoint}', dict(masterKey='{key}'))\r\n",
    "        collection = client.ReadCollection(collection_link='dbs/{database}/colls/{collection}')\r\n",
    "    except Exception as e:\r\n",
    "        collection = e\r\n",
    "\r\n",
    "def run(input_json):\r\n",
    "    try:\r\n",
    "        # Query them in SQL\r\n",
    "        id = str(json.loads(json.loads(input_json)[0])['id'])\r\n",
    "        query = dict(query='SELECT * FROM c WHERE c.id = \"' + id +'\"')\r\n",
    "        options = dict(partitionKey=str(id))\r\n",
    "        document_link = 'dbs/{database}/colls/{collection}/docs/' + id\r\n",
    "        result = client.ReadDocument(document_link, options);  \r\n",
    "    except Exception as e:\r\n",
    "        result = str(e)\r\n",
    "    return json.dumps(str(result))\r\n",
    "\"\"\".format(key=dbsecrets['Masterkey'], \r\n",
    "           endpoint=dbsecrets['Endpoint'], \r\n",
    "           database=dbsecrets['Database'], \r\n",
    "           collection=dbsecrets['Collection'])\r\n",
    "\r\n",
    "# Python 文字列の有効性をテストする\r\n",
    "exec(score_sparkml)\r\n",
    "\r\n",
    "with open(\"score_sparkml.py\", \"w\") as file:\r\n",
    "    file.write(score_sparkml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの登録:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model mvl-als-reco.mml\n",
      "mvl-als-reco.mml AML trained model 1\n"
     ]
    }
   ],
   "source": [
    "mymodel = Model.register(\r\n",
    "    model_path=model_name,  # これはローカル ファイルへのポイント\r\n",
    "    model_name=model_name,  # これは登録されているモデル名\r\n",
    "    description=\"AML trained model\",\r\n",
    "    workspace=ws\r\n",
    ")\r\n",
    "\r\n",
    "print(mymodel.name, mymodel.description, mymodel.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 AKS にサービスとしてモデルを展開"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 モデルの環境を作成:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(name='sparkmlenv')\r\n",
    "\r\n",
    "# ベース イメージとして Microsoft/mmlspark のパブリック イメージを指定する\r\n",
    "env.docker.base_image=\"microsoft/mmlspark:0.15\"\r\n",
    "\r\n",
    "pip = [\r\n",
    "    'azureml-defaults', \r\n",
    "    'numpy==1.14.2', \r\n",
    "    'scikit-learn==0.19.1', \r\n",
    "    'pandas', \r\n",
    "    'pydocumentdb'\r\n",
    "]\r\n",
    "\r\n",
    "# 推論に必要な依存関係を追加する\r\n",
    "env.python.conda_dependencies = CondaDependencies.create(pip_packages=pip)\r\n",
    "env.inferencing_stack_version = \"latest\"\r\n",
    "\r\n",
    "# Spark パッケージの追加\r\n",
    "env.spark.precache_packages = True\r\n",
    "env.spark.repositories = [\"https://mmlspark.azureedge.net/maven\"]\r\n",
    "env.spark.packages= [\r\n",
    "    SparkPackage(\"com.microsoft.ml.spark\", \"mmlspark_2.11\", \"0.15\"),\r\n",
    "    SparkPackage(\"com.microsoft.azure\", artifact=\"azure-storage\", version=\"2.0.0\"),\r\n",
    "    SparkPackage(group=\"org.apache.hadoop\", artifact=\"hadoop-azure\", version=\"2.7.0\")\r\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 コンテナーを実行する AKS クラスターを作成\r\n",
    "クラスタサイズによっては、20～30 分かかる場合があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating.......................................................................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n"
     ]
    }
   ],
   "source": [
    "# クラスタが存在していないことを確認\r\n",
    "try:\r\n",
    "    aks_target = ComputeTarget(workspace=ws, name=aks_name)\r\n",
    "    print(\"Found existing cluster, use it.\")\r\n",
    "except ComputeTargetException:\r\n",
    "    # 既定の構成を使用してクラスターを作成 (カスタマイズするパラメーターも提供可能)\r\n",
    "    prov_config = AksCompute.provisioning_configuration()\r\n",
    "    aks_target = ComputeTarget.create(\r\n",
    "        workspace=ws, \r\n",
    "        name=aks_name, \r\n",
    "        provisioning_configuration=prov_config\r\n",
    "    )\r\n",
    "    aks_target.wait_for_completion(show_output = True)\r\n",
    "    print(aks_target.provisioning_state)\r\n",
    "    # エラー ログを確認するには、print(aks_target.provisioning_errors) を実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 コンテナー イメージを AKS に展開:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running....................................................................................................................\n",
      "SucceededAKS service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# 環境、スコアリング スクリプトを使用して推論構成を作成する\r\n",
    "inference_config = InferenceConfig(\r\n",
    "    environment=env,\r\n",
    "    entry_script=\"score_sparkml.py\"\r\n",
    ")\r\n",
    "\r\n",
    "# Web サービスの構成の設定 (ここでは App Insights でデフォルトを使用)\r\n",
    "aks_config = AksWebservice.deploy_configuration(enable_app_insights=True)\r\n",
    "\r\n",
    "# 単一コマンドを使用した Web サービスの作成\r\n",
    "try:\r\n",
    "    aks_service = Model.deploy(\r\n",
    "        workspace=ws,\r\n",
    "        models=[mymodel],\r\n",
    "        name=service_name,\r\n",
    "        inference_config=inference_config,\r\n",
    "        deployment_config=aks_config,\r\n",
    "        deployment_target=aks_target\r\n",
    "    )\r\n",
    "    aks_service.wait_for_deployment(show_output=True)\r\n",
    "except WebserviceException:\r\n",
    "    # 既存のサービスを取得\r\n",
    "    aks_service = Webservice(ws, name=service_name)\r\n",
    "    print(\"Retrieved existing service\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 AKS モデル サービスを呼び出す\r\n",
    "デプロイ後、サービスはユーザー ID で呼び出すことができます 。次のスクリプトは、レコメンデーション サービス API を呼び出し、指定されたユーザー ID の結果を表示する方法を示しています："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"MovieId\": [\n",
      "        320,\n",
      "        1589,\n",
      "        262,\n",
      "        1344,\n",
      "        958,\n",
      "        889,\n",
      "        1368,\n",
      "        645,\n",
      "        919,\n",
      "        1137\n",
      "    ],\n",
      "    \"id\": \"496\",\n",
      "    \"_rid\": \"34hEAIe9pterAQAAAAAACA==\",\n",
      "    \"_self\": \"dbs/34hEAA==/colls/34hEAIe9ptc=/docs/34hEAIe9pterAQAAAAAACA==/\",\n",
      "    \"_etag\": \"6d006b74-0000-0100-0000-5f25f0550000\",\n",
      "    \"_attachments\": \"attachments/\",\n",
      "    \"_ts\": 1596321877\n",
      "}\n",
      "Full run took 0.05 seconds\n"
     ]
    }
   ],
   "source": [
    "import json\r\n",
    "\r\n",
    "scoring_url = aks_service.scoring_uri\r\n",
    "service_key = aks_service.get_keys()[0]\r\n",
    "\r\n",
    "input_data = '[\"{\\\\\"id\\\\\":\\\\\"496\\\\\"}\"]'.encode()\r\n",
    "\r\n",
    "req = urllib.request.Request(scoring_url, data=input_data)\r\n",
    "req.add_header(\"Authorization\",\"Bearer {}\".format(service_key))\r\n",
    "req.add_header(\"Content-Type\",\"application/json\")\r\n",
    "\r\n",
    "with Timer() as t: \r\n",
    "    with urllib.request.urlopen(req) as result:\r\n",
    "        res = result.read()\r\n",
    "        resj = json.loads(\r\n",
    "            # json オブジェクトに解析するためのクリーンアップ\r\n",
    "            res.decode(\"utf-8\")\r\n",
    "            .replace(\"\\\\\", \"\")\r\n",
    "            .replace('\"', \"\")\r\n",
    "            .replace(\"'\", '\"')\r\n",
    "        )\r\n",
    "        print(json.dumps(resj, indent=4))\r\n",
    "    \r\n",
    "print(\"Full run took %.2f seconds\" % t.interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix - AzureML を使用したリアルタイム スコアリング\r\n",
    "\r\n",
    "以前のセルでは、Cosmos DB を利用して、リアルタイム・サービスの推奨結果をキャッシュしました。それ以外にも、展開したモデルを使用してオンデマンドでレコメンデーション結果を生成することもできます。次のスクリプトは、登録されたモデルを読み込み、レコメンデーションのために使用します：\r\n",
    "\r\n",
    "* *score_sparkml.py*\r\n",
    "    ```\r\n",
    "    import json\r\n",
    "    import os\r\n",
    "    from pyspark.ml.recommendation import ALSModel\r\n",
    "\r\n",
    "    # Note, set `model_name`, `userCol`, and `itemCol` defined earlier.\r\n",
    "    model_name = \"mvl-als-reco.mml\"\r\n",
    "    userCol = \"UserId\"\r\n",
    "    itemCol = \"MovieId\"\r\n",
    "\r\n",
    "    def init(local=False):\r\n",
    "        global model\r\n",
    "\r\n",
    "        # Load ALS model.\r\n",
    "        model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), model_name)\r\n",
    "        model = ALSModel.load(model_path)\r\n",
    "\r\n",
    "    def run(input_json):\r\n",
    "        js = json.loads(json.loads(input_json)[0])\r\n",
    "        id = str(js['id'])\r\n",
    "        k = js.get('k', 10)\r\n",
    "\r\n",
    "        # Use the model to get recommendation.\r\n",
    "        recs = model.recommendForAllUsers(k)\r\n",
    "        recs_topk = recs.withColumn('id', recs[userCol].cast(\"string\")).select(\r\n",
    "            'id', \"recommendations.\" + itemCol\r\n",
    "        )\r\n",
    "        result = recs_topk[recs_topk.id==id].collect()[0].asDict()\r\n",
    "\r\n",
    "        return json.dumps(str(result))\r\n",
    "    ```\r\n",
    "\r\n",
    "* AKS モデル サービスを呼び出す\r\n",
    "    ```\r\n",
    "    # Get a recommendation of 10 movies\r\n",
    "    input_data = '[\"{\\\\\"id\\\\\":\\\\\"496\\\\\",\\\\\"k\\\\\":10}\"]'.encode()\r\n",
    "\r\n",
    "    req = urllib.request.Request(scoring_url, data=input_data)\r\n",
    "    req.add_header(\"Authorization\",\"Bearer {}\".format(service_key))\r\n",
    "    req.add_header(\"Content-Type\",\"application/json\")\r\n",
    "    \r\n",
    "    ...\r\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reco_pyspark)",
   "language": "python",
   "name": "reco_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "name": "ALS_Movie_Example",
  "notebookId": 3793436040750096,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}