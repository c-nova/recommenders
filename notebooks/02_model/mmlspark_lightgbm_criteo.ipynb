{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n\n<i>Licensed under the MIT License.</i>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Spark の LightGBM を使用したコンテンツベースのパーソナライゼーション\n\nこのノートブックでは、コンテンツベースのパーソナライゼーション シナリオで [MMLSpark](https://github.com/Azure/mmlspark) を使用して Spark で [LightGBM](https://github.com/Microsoft/Lightgbm) モデルをトレーニングする方法の簡単な例を示します。\n\nクリックスルー率(CTR)の最適化に使用できるウェブサイト広告のよく知られたデータセットである[CRITEO データセット](https://www.kaggle.com/c/criteo-display-ad-challenge)を使用しています。データセットは、一連の数値およびカテゴリのフィーチャーと、新たに追加されたクリックされたかどうかを示すバイナリ ラベルで構成されています。\n\nモデルは[LightGBM](https://github.com/Microsoft/Lightgbm)に基づいており、ツリーベースの学習アルゴリズムを使用するグラデーションブーストフレームワークです。最後に、\n[MMLSpark](https://github.com/Azure/mmlspark) ライブラリを使用することで、LightGBM を Spark 環境で呼び出し、分散して計算できます。\n\nこのシナリオは**暗黙的なフィードバック**の良い例であり、バイナリラベルはユーザーとアイテムの間の相互作用を示します。これは、ユーザーがコンテンツを明示的に評価する明示的なフィードバック (1 から 5 など) とは対照的です。\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## グローバル設定とインポート"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "このノートブックは、DSVM または Azure Databricks の Spark 環境で実行できます。インストールプロセスの詳細については、[セットアップ手順](../../SETUP.md)を参照してください。\n\n**Azure Databricksでの注意:**\n\n* Azure Databricks で正しい依存関係の設定を簡略化するために、Python スクリプトが用意されています。詳細については、```python scripts/databricks_install.py -h``` を実行してください。\n* MMLSpark は、自動スケールが有効になっているクラスターで実行しないでください。このノートブックを実行する前に、Azure Databricks クラスター構成でフラグを無効にします。"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import os\nimport sys\n\nsys.path.append(\"../../\")\n\nimport pyspark\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml.feature import FeatureHasher\nimport papermill as pm\n\nfrom reco_utils.common.spark_utils import start_or_get_spark\nfrom reco_utils.common.notebook_utils import is_databricks\nfrom reco_utils.dataset.criteo import load_spark_df\nfrom reco_utils.dataset.spark_splitters import spark_random_split\n\n# Setup MML Spark\nif not is_databricks():\n    # databricks_install スクリプトから MML Spark の maven コーディネートを取得する\n    from scripts.databricks_install import MMLSPARK_INFO\n    packages = [MMLSPARK_INFO[\"maven\"][\"coordinates\"]]\n    repo = MMLSPARK_INFO[\"maven\"].get(\"repo\")\n    spark = start_or_get_spark(packages=packages, repository=repo)\n    dbutils = None\n    print(\"MMLSpark version: {}\".format(MMLSPARK_INFO['maven']['coordinates']))\n\nfrom mmlspark import ComputeModelStatistics\nfrom mmlspark import LightGBMClassifier\n\nprint(\"System version: {}\".format(sys.version))\nprint(\"PySpark version: {}\".format(pyspark.version.__version__))\n",
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "MMLSpark version: com.microsoft.ml.spark:mmlspark_2.11:0.16.dev8+2.g6a5318b\nSystem version: 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \n[GCC 7.3.0]\nPySpark version: 2.3.0\n"
        }
      ]
    },
    {
      "metadata": {
        "tags": [
          "parameters"
        ],
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Criteo データのサイズ。\"sample\" または \"full\" で指定\nDATA_SIZE = \"sample\"\n\n# LightGBM パラメータ\n# パラメータの詳細: https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\nNUM_LEAVES = 32\nNUM_ITERATIONS = 50\nLEARNING_RATE = 0.1\nFEATURE_FRACTION = 0.8\nEARLY_STOPPING_ROUND = 10\n\n# モデル名\nMODEL_NAME = 'lightgbm_criteo.mml'",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## データ準備\n [Criteo Display Advertising Challenge](https://www.kaggle.com/c/criteo-display-ad-challenge) (Criteo DAC) データセットは、CTR 予測モデルを開発するための業界のベンチマーク データセットとしてよく知られており、研究論文で頻繁に使用されています。元のデータセットには 45 百万行を超える行が含まれていますが、100,000 行を持つダウンサンプリングされたデータセットもあります (これは DATA_SIZE = \"sample\"を設定することで使用できます)。各行は Criteo が提供する表示広告に対応し、最初の列は、この広告がクリックされたかどうかを示します。\n\nデータセットには 1 つのラベル列と 39 個のフィーチャ列があり、13 列が整数値 (int00-int12) で、26 列がカテゴリ フィーチャ (cat00-cat25) です。\n\n列が表すものは提供されませんが、この場合、整数値とカテゴリ値は、ユーザーおよび/または項目の内容を表す特徴と見なすことができます。ラベルはバイナリであり、ユーザーのアイテムとの対話を示す暗黙的なフィードバックの例です。このデータセットを使用すると、使用可能なユーザーおよびアイテムコンテンツ機能に基づいて、ユーザーがアイテムを操作する確率を予測するモデルを構築する方法を示すことができます。"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "raw_data = load_spark_df(size=DATA_SIZE, spark=spark, dbutils=dbutils)\n# データの可視化\nraw_data.limit(2).toPandas().head()",
      "execution_count": 3,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "8.79MB [00:00, 32.6MB/s]                            \n"
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>int00</th>\n      <th>int01</th>\n      <th>int02</th>\n      <th>int03</th>\n      <th>int04</th>\n      <th>int05</th>\n      <th>int06</th>\n      <th>int07</th>\n      <th>int08</th>\n      <th>...</th>\n      <th>cat16</th>\n      <th>cat17</th>\n      <th>cat18</th>\n      <th>cat19</th>\n      <th>cat20</th>\n      <th>cat21</th>\n      <th>cat22</th>\n      <th>cat23</th>\n      <th>cat24</th>\n      <th>cat25</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1382</td>\n      <td>4</td>\n      <td>15</td>\n      <td>2</td>\n      <td>181</td>\n      <td>...</td>\n      <td>e5ba7672</td>\n      <td>f54016b9</td>\n      <td>21ddcdc9</td>\n      <td>b1252a9d</td>\n      <td>07b5194c</td>\n      <td>None</td>\n      <td>3a171ecb</td>\n      <td>c5c50484</td>\n      <td>e8b83407</td>\n      <td>9727dd16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>44</td>\n      <td>1</td>\n      <td>102</td>\n      <td>8</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>...</td>\n      <td>07c540c4</td>\n      <td>b04e4670</td>\n      <td>21ddcdc9</td>\n      <td>5840adea</td>\n      <td>60f6221e</td>\n      <td>None</td>\n      <td>3a171ecb</td>\n      <td>43f13e8b</td>\n      <td>e8b83407</td>\n      <td>731c3655</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 40 columns</p>\n</div>",
            "text/plain": "   label  int00  int01  int02  int03  int04  int05  int06  int07  int08  ...  \\\n0      0      1      1      5      0   1382      4     15      2    181  ...   \n1      0      2      0     44      1    102      8      2      2      4  ...   \n\n      cat16     cat17     cat18     cat19     cat20 cat21     cat22     cat23  \\\n0  e5ba7672  f54016b9  21ddcdc9  b1252a9d  07b5194c  None  3a171ecb  c5c50484   \n1  07c540c4  b04e4670  21ddcdc9  5840adea  60f6221e  None  3a171ecb  43f13e8b   \n\n      cat24     cat25  \n0  e8b83407  9727dd16  \n1  e8b83407  731c3655  \n\n[2 rows x 40 columns]"
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### フィーチャーの処理\n提供されるフィーチャー データには、整数とカテゴリ フィーチャー フィールドの両方で多くの欠損値があります。さらに、カテゴリ フィーチャーには多くの異なる値が含まれるため、フィーチャ データを効果的にクリーニングして表現することは、モデルをトレーニングする前に重要な手順です。\n\n値が欠落しているフィーチャーと高いカーディナリティを持つ両方のフィーチャを管理する最も簡単な方法の 1 つは、ハッシュトリックを使用することです。[FeatureHasher](http://spark.apache.org/docs/latest/ml-features.html#featurehasher) トランスフォーマーは整数値を渡し、カテゴリ フィーチャを低次元のスパース ベクトルにハッシュします。\n\nまず、トレーニングとテストのためにデータセットがランダムに分割され、各データセットに機能処理が適用されます。"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "raw_train, raw_test = spark_random_split(raw_data, ratio=0.8, seed=42)",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "columns = [c for c in raw_data.columns if c != 'label']\nfeature_processor = FeatureHasher(inputCols=columns, outputCol='features')",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "train = feature_processor.transform(raw_train)\ntest = feature_processor.transform(raw_test)",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## モデルトレーニング\nMMLSpark では、`LightGBMClassifier` クラスを使用して、バイナリ分類の LightGBM 実装が呼び出され、目的変数を `バイナリ` として指定します。この場合、正のラベルの出現率は非常に低いので、`isUnbalance` フラグを true に設定すると、この不均衡を緩和するのに役立ちます。<br><br>\n\n### ハイパーパラメータ\nSpark で LightGBM 分類器をトレーニングするための主要な[ハイパーパラメーター](https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters-Tuning.rst)の一部を次に示します:\n\n- `numLeaves`: 各ツリーの葉の数\n- `numIterations`: ブーストを適用する反復回数\n- `learningRate`: ツリー間でのトレーニングの学習率\n- `featureFraction`: ツリーのトレーニングに使用されるフィーチャーの割合\n- `earlyStoppingRound`: オーバーフィットを避けるために早期停止を適用できるラウンド"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "lgbm = LightGBMClassifier(\n    labelCol=\"label\",\n    featuresCol=\"features\",\n    objective=\"binary\",\n    isUnbalance=True,\n    boostingType=\"gbdt\",\n    boostFromAverage=True,\n    baggingSeed=42,\n    numLeaves=NUM_LEAVES,\n    numIterations=NUM_ITERATIONS,\n    learningRate=LEARNING_RATE,\n    featureFraction=FEATURE_FRACTION,\n    earlyStoppingRound=EARLY_STOPPING_ROUND\n)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### モデルのトレーニングと評価"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "model = lgbm.fit(train)\npredictions = model.transform(test)",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "evaluator = (\n    ComputeModelStatistics()\n    .setScoredLabelsCol(\"prediction\")\n    .setLabelCol(\"label\")\n    .setEvaluationMetric(\"AUC\")\n)\n\nresult = evaluator.transform(predictions)\nauc = result.select(\"AUC\").collect()[0][0]\nresult.show()",
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "+---------------+------------------+\n|evaluation_type|               AUC|\n+---------------+------------------+\n| Classification|0.6870253907336659|\n+---------------+------------------+\n\n"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# テストで使用した paermill の結果の記録\npm.record(\"auc\", auc)",
      "execution_count": 10,
      "outputs": [
        {
          "data": {
            "application/papermill.record+json": {
              "auc": 0.68702539073366586
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## モデルの保存\nフィーチャー処理やモデル予測を含む生データを操作するための完全なパイプラインは、別のワークフローで使用するために保存および再ロードできます。"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# モデルの保存\npipeline = PipelineModel(stages=[feature_processor, model])\npipeline.write().overwrite().save(MODEL_NAME)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 参考文献\n\\[1\\] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. LightGBM: A highly efficient gradient boosting decision tree. In Advances in Neural Information Processing Systems. 3146–3154. https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf <br>\n\\[2\\] MML Spark: https://mmlspark.blob.core.windows.net/website/index.html <br>\n"
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}